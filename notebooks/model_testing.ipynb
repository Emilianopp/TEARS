{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/e/emiliano.penaloza/llm4rec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-16 11:25:02,441\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/home/mila/e/emiliano.penaloza/LLM4REC/notebooks/../model/MF.py:11: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import re \n",
    "import logging\n",
    "import json\n",
    "from pprint import pprint as pp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "import datetime\n",
    "from dateutil import tz\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch\n",
    "import pickle\n",
    "import math\n",
    "import warnings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from model.decoderMLP import decoderMLP, decoderAttention, movieTransformer\n",
    "from helper.sampler import NegSampler, negsamp_vectorized_bsearch_preverif\n",
    "from model.MF import MatrixFactorization, MatrixFactorizationLLM\n",
    "from trainer.training_utils import *\n",
    "from helper.eval_metrics import *\n",
    "from helper.dataloader import *\n",
    "from StyleTransfer.scorer import *\n",
    "from StyleTransfer.editor import RobertaEditor\n",
    "from StyleTransfer.config import get_args\n",
    "import random\n",
    "import json\n",
    "from pprint import pprint as pp\n",
    "\n",
    "\n",
    "import debugpy\n",
    "\n",
    "\n",
    "def get_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"model parameters\")\n",
    "    parser.add_argument('--seed', type=int, default=42, help='Seed for random number generator')\n",
    "    \n",
    "    parser.add_argument('--output_dir', type=str, default=\"output/\", help='Output directory path to store checkpoints.')\n",
    "    parser.add_argument('--class_name',default='../EleutherAI/gpt-neo-1.3B',type=str)\n",
    "    parser.add_argument('--topk', default=20, type=int,help=\"top-k words in masked out word prediction\")\n",
    "    parser.add_argument(\"--fluency_weight\", type=int, default=1, help='fluency')\n",
    "    parser.add_argument(\"--sem_weight\",type=int, default=1, help='semantic similarity')\n",
    "    parser.add_argument(\"--style_weight\", type=int, default=8, help='style')\n",
    "    parser.add_argument(\"--max_steps\", type=int, default=5)\n",
    "    parser.add_argument(\"--bs\",type=int,default=4,help=\"batch size\")\n",
    "    parser.add_argument('--keyword_pos', default=True, type=bool)\n",
    "    parser.add_argument(\"--early_stop\",default=True, type=bool)\n",
    "    parser.add_argument(\"--data_name\", default='ml-100k', type=str)\n",
    "    parser.add_argument(\"--embedding_module\", default='t5', type=str)\n",
    "    parser.add_argument('--debugger', action='store_true')\n",
    "\n",
    "    args, _ = parser.parse_known_args([]) \n",
    "    args.device = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu') )\n",
    "    args.device = 'cpu'\n",
    "    return args\n",
    "\n",
    "\n",
    "args = get_args()\n",
    "\n",
    "if args.debugger: \n",
    "    debugpy.listen(5678)\n",
    "    print(\"Waiting for debugger attach\")\n",
    "    debugpy.wait_for_client()\n",
    "    \n",
    "def find_string_differences(str1, str2):\n",
    "    # Find the indices where the strings differ\n",
    "    str1 = str1.split()\n",
    "    str2 = str2.split()\n",
    "    \n",
    "    diff_indices = [i for i, (c1, c2) in enumerate(zip(str1, str2)) if c1 != c2]\n",
    "\n",
    "    # Print 5 indices before and after each difference\n",
    "    for index in diff_indices:\n",
    "        start_index = max(0, index - 30)\n",
    "        end_index = min(len(str1), index + 30)\n",
    "\n",
    "\n",
    "        print(f\"Difference at index {index}:\")\n",
    "\n",
    "        print(f\"String 2: {str2[start_index:end_index]}\")\n",
    "        print(f\"String 1: {str1[start_index:end_index]}\")\n",
    "        print()\n",
    "        \n",
    "\n",
    "# Split the text into words\n",
    "def do_not_edit(text):\n",
    "    text = text[0] if not isinstance(text,str) else text\n",
    "    \n",
    "    words = text.split()\n",
    "\n",
    "    # Initialize a list to store the indices of words with ':'\n",
    "    indices_of_words_with_colon = []\n",
    "\n",
    "    # Iterate through the words to find the indices of words with ':'\n",
    "    for index, word in enumerate(words):\n",
    "        if ':' in word:\n",
    "            # Add the index to the list\n",
    "            indices_of_words_with_colon.append(index)\n",
    "\n",
    "    # Print the list of indices of words with ':'\n",
    "    return indices_of_words_with_colon\n",
    "        \n",
    "def get_preds(summaries ,USER_INDEX): \n",
    "    args.embedding_module = 't5'\n",
    "    topk= args.topk\n",
    "    embs = get_genrewise_embeddings(summaries,args, model= transformer_model )\n",
    "\n",
    "    genre_list = get_genres()\n",
    "    embs_tens = model.user_embeddings.prepare_input(embs,genre_list).to(args.device)\n",
    "\n",
    "\n",
    "    rating_pred = model.predict(embs_tens.unsqueeze(0)).cpu().detach().numpy()\n",
    "    \n",
    "    rating_pred[train_matrix[USER_INDEX].toarray() > 0] = 0\n",
    "\n",
    "\n",
    "    # reference: https://stackoverflow.com/a/23734295, https://stackoverflow.com/a/20104162\n",
    "    ind = np.argpartition(rating_pred, -topk)\n",
    "    ind = ind[:, -topk:]\n",
    "    arr_ind = rating_pred[np.arange(len(rating_pred))[:, None], ind]\n",
    "    arr_ind_argsort = np.argsort(arr_ind)[np.arange(len(rating_pred)), ::-1]\n",
    "    \n",
    "\n",
    "    ranked_items = ind[np.arange(len(rating_pred))[:, None], arr_ind_argsort]\n",
    "    recall_val = recall_at_k_one(actual_list_val[3], ranked_items[0].tolist(), 20)\n",
    "\n",
    "\n",
    "    reversed_movie_title_to_id = {v: k for k, v in movie_title_to_id.items()}\n",
    "    movie_titles_ranked = [f'{index} : {reversed_movie_title_to_id[i+1]} {id_genre_map[i+1]}' for index,i in enumerate(ranked_items[0][:20])]\n",
    "\n",
    "\n",
    "\n",
    "    return torch.tensor(ranked_items).to(args.device),torch.tensor(rating_pred).to(args.device)\n",
    "\n",
    "def make_string_dict(data):\n",
    "    \n",
    "    genre_summary_dict = {}\n",
    "    data = data[0].lower().replace('\\n',' ').replace('-','').replace('summary:','summary')\n",
    "\n",
    "    # Use regular expression to find genre and summary information\n",
    "    matches = re.finditer(r'(\\w+): (.+?)(?=\\w+:|$)', data)\n",
    "\n",
    "    # Iterate through the matches and extract genre and summary information\n",
    "    for match in matches:\n",
    "        genre, summary = match.group(1), match.group(2)\n",
    "        genre_summary_dict[genre] = summary.strip()\n",
    "\n",
    "    # Convert the dictionary to JSON\n",
    "    return genre_summary_dict\n",
    "\n",
    "def make_dict_string(data):\n",
    "    data_out = []\n",
    "    for d in data:\n",
    "        user_str = ''\n",
    "        for k,v in d.items():\n",
    "            user_str += f\" {k}: {v}\"\n",
    "        data_out.append(user_str)\n",
    "        \n",
    "    return data_out\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "# %%\n",
    "\n",
    "def style_ranker(text,movie_id =57 ,user_id=None,original_index =16,model= None ):\n",
    "    preds_new,scores = get_preds(make_string_dict(text),user_id)\n",
    "    if movie_id in preds_new: \n",
    "        return scores[:,movie_id],preds_new[0]\n",
    "    else:\n",
    "        return torch.tensor([0]).to(args.device),torch.tensor([0]).to(args.device)\n",
    "    \n",
    "    \n",
    "# %%\n",
    "lr= 0.00001\n",
    "epochs = 400\n",
    "num_heads = 6\n",
    "cosine = False\n",
    "num_layers = 3\n",
    "output_emb = 64\n",
    "embedding_dim = 768\n",
    "saved_path = f'../saved_model/ml-100k/attn_best_model_{lr}_{epochs}_{num_heads}_{cosine}_{num_layers}.pth'\n",
    "\n",
    "model_path = saved_path + '_best_model.pth'\n",
    "embedder_path = saved_path + '_embedder.pth'\n",
    "item_embeddings_path = saved_path + '_item_embeddings.pth'\n",
    "user_embeddings_path = saved_path + '_user_embeddings.pth'\n",
    "model_rankings_path = saved_path + '_rankings_matrix.npy'\n",
    "id_genre_map = map_id_to_genre('../data/ml-100k/movies.dat')\n",
    "\n",
    "# 1. Data Loading & Preprocessing\n",
    "train_data = load_dataset(\"../data_preprocessed/ml-100k/data_split/train_set_leave_one.json\")\n",
    "valid_data = load_dataset(\"../data_preprocessed/ml-100k/data_split/valid_set_leave_one.json\")\n",
    "test_data = load_dataset(\"../data_preprocessed/ml-100k/data_split/test_set_leave_one.json\")\n",
    "movie_title_to_id = map_title_to_id(\"../data/ml-100k/movies.dat\")\n",
    "\n",
    "train_data = convert_titles_to_ids(train_data, movie_title_to_id)\n",
    "valid_data = convert_titles_to_ids(valid_data, movie_title_to_id)\n",
    "test_data = convert_titles_to_ids(test_data, movie_title_to_id)\n",
    "\n",
    "train_matrix, actual_list_val, actual_list_test = create_train_matrix_and_actual_lists(train_data, valid_data,\n",
    "                                                                                        test_data, movie_title_to_id)\n",
    "train_matrix = csr_matrix(train_matrix)  # Convert train_matrix to a CSR matrix\n",
    "\n",
    "num_users, num_items = train_matrix.shape\n",
    "args.output_emb = 64\n",
    "user_embedder = decoderAttention(embedding_dim,num_heads,num_layers,output_emb, 0  ,bias = True)\n",
    "model = MatrixFactorizationLLM(num_users, user_embedder,num_items, args).to(args.device)\n",
    "rankings_true = np.load(model_rankings_path)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path,map_location=torch.device('cuda')))\n",
    "user_embedder.load_state_dict(torch.load(user_embeddings_path,map_location=torch.device('cuda')))\n",
    "model.user_embeddings = user_embedder\n",
    "model.eval()\n",
    "\n",
    "transformer_model = SentenceTransformer('sentence-transformers/sentence-t5-large').to(args.device) \n",
    "\n",
    "with open('../saved_user_summary/ml-100k/user_summary_gpt3.5_in1_title0_full.json','r') as j:\n",
    "    data = json.load(j)\n",
    "    data = {int(key): value for key, value in data.items()}\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "last_items = rankings_true[:,19]\n",
    "data =[v for k,v in data.items()]\n",
    "\n",
    "\n",
    "rankings = np.load('./rankings.npy' )\n",
    "\n",
    "data = make_dict_string(data)\n",
    "\n",
    "args.max_len = 514\n",
    "# print(f\"{args.max_len=}\")\n",
    "# exit(0)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Editor built\n"
     ]
    }
   ],
   "source": [
    "editor = RobertaEditor(args).to(device)\n",
    "sahc = SteepHC(args, editor).to(device)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "of_dir = 'results/' + args.output_dir\n",
    "\n",
    "if not os.path.exists(of_dir):\n",
    "    os.makedirs(of_dir)\n",
    "\n",
    "\n",
    "bsz = args.bs\n",
    "\n",
    "\n",
    "tzone = tz.gettz('')\n",
    "timestamp = datetime.datetime.now().astimezone(tzone).strftime('%Y-%m-%d_%H:%M:%S')\n",
    "\n",
    "output_file =f'{timestamp}_{dst}_seed={str(args.seed)}_{str(args.style_weight)}.txt'\n",
    "\n",
    "log_txt_path=os.path.join(of_dir, output_file.split('.txt')[0] + '.log')\n",
    "\n",
    "\n",
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(format='',\n",
    "                    filename=log_txt_path,\n",
    "                    filemode='w',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "word_pairs ={\"ca n't\": \"can not\", \"wo n't\": \"will not\"}\n",
    "logging.info(args)\n",
    "\n",
    "def print_es():\n",
    "    print(\"Early Stopping!\")\n",
    "    logging.info(\"Early Stopping!\")\n",
    "    \n",
    "num_batches = len(data)//bsz\n",
    "result_d = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked_inputs=[\"action: summary: action-packed movies from the 90s with a mix of cyberpunk, post-apocalyptic, and martial arts themes. these films feature intense action sequences and are directed by renowned filmmakers. drama: summary: a collection of drama films ranging from disaster survival, epic western, historical biographical, romantic, and psychological thriller. these films explore themes of love, loss, personal struggles, and the human condition. romance: summary: a collection of romantic movies from various genres including drama, comedy, musical, and fantasy. these films explore themes of love and relationships, featuring a mix of well-known actors and diverse storylines. scifi: summary: a collection of sci-fi films ranging from space operas to post-apocalyptic adventures, with elements of cyberpunk and dystopia. the movies explore themes of technology, survival, and thrilling action, featuring memorable characters and imaginative settings. thriller: summary: a collection of thrilling movies with elements of crime, suspense, and science fiction. the films feature a variety of genres including erotic thriller, cyberpunk, and independent drama. the cast includes notable actors such as ray liotta, linda fiorent crime: summary: a collection of crime films from the mid-90s, including gangster comedies, epic crime dramas, cyberpunk thrillers, and action-packed sci-fi flicks. comedy: summary: a collection of comedy films spanning different themes and genres, including children's comedy, adventure comedy fantasy, prank calls, historical comedy-drama, action comedy, romantic comedy, and farce black comedy. children: summary: a collection of coming-of-age, fantasy, adventure, comedy, and family films that will entertain children and provide a fun and enjoyable experience. adventure: summary: adventure movies from the 1990s with a mix of drama, fantasy, and superhero themes. animation: summary: animated films that belong to the animation genre, providing entertainment with adventure, music, and historical themes. fantasy: summary: a collection of fantasy films ranging from family adventures to magical realism, including stories about mythical creatures, mystical worlds, and extraordinary quests. documentary: summary: a collection of documentary films exploring various subjects, including basketball dreams, mockumentary, hip-hop music, hollywood's infamous madam, fashion models, and notable individuals like nico and jean seberg. the films offer a glimpse into different worlds mystery: summary: a collection of mysterious and suspenseful films that explore crime, psychological thrillers, and science fiction. these movies delve into the world of detectives, investigations, and the after-effects of unexpected events. horror: summary: a collection of horror films that explore vampires, psychological thrillers, and supernatural elements. a vampire gothic horror, a vampire black comedy, a psychological thriller, an action horror, a fantasy thriller, a direct-to-video horror, and a war: summary: a collection of war-inspired films <mask> various genres, including action thrillers, historical dramas, biographical dramas, satirical comedies, and dramatic portrayals of real-life events.\"]\n",
      "mask_inputs=array([\"action: summary: action-packed movies from the 90s with a mix of cyberpunk, post-apocalyptic, and martial arts themes. these films feature intense action sequences and are directed by renowned filmmakers. drama: summary: a collection of drama films ranging from disaster survival, epic western, historical biographical, romantic, and psychological thriller. these films explore themes of love, loss, personal struggles, and the human condition. romance: summary: a collection of romantic movies from various genres including drama, comedy, musical, and fantasy. these films explore themes of love and relationships, featuring a mix of well-known actors and diverse storylines. scifi: summary: a collection of sci-fi films ranging from space operas to post-apocalyptic adventures, with elements of cyberpunk and dystopia. the movies explore themes of technology, survival, and thrilling action, featuring memorable characters and imaginative settings. thriller: summary: a collection of thrilling movies with elements of crime, suspense, and science fiction. the films feature a variety of genres including erotic thriller, cyberpunk, and independent drama. the cast includes notable actors such as ray liotta, linda fiorent crime: summary: a collection of crime films from the mid-90s, including gangster comedies, epic crime dramas, cyberpunk thrillers, and action-packed sci-fi flicks. comedy: summary: a collection of comedy films spanning different themes and genres, including children's comedy, adventure comedy fantasy, prank calls, historical comedy-drama, action comedy, romantic comedy, and farce black comedy. children: summary: a collection of coming-of-age, fantasy, adventure, comedy, and family films that will entertain children and provide a fun and enjoyable experience. adventure: summary: adventure movies from the 1990s with a mix of drama, fantasy, and superhero themes. animation: summary: animated films that belong to the animation genre, providing entertainment with adventure, music, and historical themes. fantasy: summary: a collection of fantasy films ranging from family adventures to magical realism, including stories about mythical creatures, mystical worlds, and extraordinary quests. documentary: summary: a collection of documentary films exploring various subjects, including basketball dreams, mockumentary, hip-hop music, hollywood's infamous madam, fashion models, and notable individuals like nico and jean seberg. the films offer a glimpse into different worlds mystery: summary: a collection of mysterious and suspenseful films that explore crime, psychological thrillers, and science fiction. these movies delve into the world of detectives, investigations, and the after-effects of unexpected events. horror: summary: a collection of horror films that explore vampires, psychological thrillers, and supernatural elements. a vampire gothic horror, a vampire black comedy, a psychological thriller, an action horror, a fantasy thriller, a direct-to-video horror, and a war: summary: a collection of war-inspired films <mask> various genres, including action thrillers, historical dramas, biographical dramas, satirical comedies, and dramatic portrayals of real-life events.\"],\n",
      "      dtype='<U3217')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked_inputs=[\"action: summary: action-packed movies from the 90s with a mix of cyberpunk, post-apocalyptic, and martial arts themes. these films feature intense action sequences and are directed by renowned filmmakers. drama: summary: a collection of drama films ranging from disaster survival, epic western, historical biographical, romantic, and psychological thriller. these films explore themes of love, loss, personal struggles, and the human condition. romance: summary: a collection of romantic movies from various genres including drama, comedy, musical, and fantasy. these films explore themes of love and relationships, featuring a mix of well-known actors and diverse storylines. scifi: summary: a collection of sci-fi films ranging from space operas to post-apocalyptic adventures, with elements of cyberpunk and dystopia. the movies explore themes of technology, survival, and thrilling action, featuring memorable characters and imaginative settings. thriller: summary: a collection of thrilling movies with elements of crime, suspense, and science fiction. the films feature a variety of genres including erotic thriller, cyberpunk, and independent drama. the cast includes notable actors such as ray liotta, linda fiorent crime: summary: a collection of crime films from the mid-90s, including gangster comedies, epic crime dramas, cyberpunk thrillers, and action-packed sci-fi flicks. comedy: summary: a collection of comedy films spanning different themes and genres, including children's comedy, adventure comedy fantasy, prank calls, historical comedy-drama, action comedy, romantic comedy, and farce black comedy. children: summary: a collection of coming-of-age, fantasy, adventure, comedy, and family films that will entertain children and provide a fun and enjoyable experience. adventure: summary: adventure movies from the 1990s with a mix of drama, fantasy, and superhero themes. animation: summary: animated films that belong to the animation genre, providing entertainment with adventure, music, and historical themes. fantasy: summary: a collection of fantasy films ranging from family adventures to magical realism, including stories about mythical creatures, mystical worlds, and extraordinary quests. documentary: summary: a collection of documentary films exploring various subjects, including basketball dreams, mockumentary, hip-hop music, hollywood's infamous madam, fashion models, and notable individuals like nico and jean seberg. the films offer a glimpse into different worlds mystery: summary: a collection of mysterious and suspenseful films that explore crime, psychological thrillers, and science fiction. these movies delve into the world of detectives, investigations, and the after-effects of unexpected events. horror: summary: a collection of horror films that explore vampires, psychological thrillers, and supernatural elements. a vampire gothic horror, a vampire black comedy, a psychological thriller, an action horror, a fantasy thriller, a direct-to-video horror, and a war: summary: a collection of war-inspired films <mask> from various genres, including action thrillers, historical dramas, biographical dramas, satirical comedies, and dramatic portrayals of real-life events.\"]\n",
      "mask_inputs=array([\"action: summary: action-packed movies from the 90s with a mix of cyberpunk, post-apocalyptic, and martial arts themes. these films feature intense action sequences and are directed by renowned filmmakers. drama: summary: a collection of drama films ranging from disaster survival, epic western, historical biographical, romantic, and psychological thriller. these films explore themes of love, loss, personal struggles, and the human condition. romance: summary: a collection of romantic movies from various genres including drama, comedy, musical, and fantasy. these films explore themes of love and relationships, featuring a mix of well-known actors and diverse storylines. scifi: summary: a collection of sci-fi films ranging from space operas to post-apocalyptic adventures, with elements of cyberpunk and dystopia. the movies explore themes of technology, survival, and thrilling action, featuring memorable characters and imaginative settings. thriller: summary: a collection of thrilling movies with elements of crime, suspense, and science fiction. the films feature a variety of genres including erotic thriller, cyberpunk, and independent drama. the cast includes notable actors such as ray liotta, linda fiorent crime: summary: a collection of crime films from the mid-90s, including gangster comedies, epic crime dramas, cyberpunk thrillers, and action-packed sci-fi flicks. comedy: summary: a collection of comedy films spanning different themes and genres, including children's comedy, adventure comedy fantasy, prank calls, historical comedy-drama, action comedy, romantic comedy, and farce black comedy. children: summary: a collection of coming-of-age, fantasy, adventure, comedy, and family films that will entertain children and provide a fun and enjoyable experience. adventure: summary: adventure movies from the 1990s with a mix of drama, fantasy, and superhero themes. animation: summary: animated films that belong to the animation genre, providing entertainment with adventure, music, and historical themes. fantasy: summary: a collection of fantasy films ranging from family adventures to magical realism, including stories about mythical creatures, mystical worlds, and extraordinary quests. documentary: summary: a collection of documentary films exploring various subjects, including basketball dreams, mockumentary, hip-hop music, hollywood's infamous madam, fashion models, and notable individuals like nico and jean seberg. the films offer a glimpse into different worlds mystery: summary: a collection of mysterious and suspenseful films that explore crime, psychological thrillers, and science fiction. these movies delve into the world of detectives, investigations, and the after-effects of unexpected events. horror: summary: a collection of horror films that explore vampires, psychological thrillers, and supernatural elements. a vampire gothic horror, a vampire black comedy, a psychological thriller, an action horror, a fantasy thriller, a direct-to-video horror, and a war: summary: a collection of war-inspired films <mask> from various genres, including action thrillers, historical dramas, biographical dramas, satirical comedies, and dramatic portrayals of real-life events.\"],\n",
      "      dtype='<U3222')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Making Edits: 100%|██████████| 3/3 [00:04<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked_inputs=[\"action: summary: action-packed movies from the 90s with a mix of cyberpunk, post-apocalyptic, and martial arts themes. these films feature intense action sequences and are directed by renowned filmmakers. drama: summary: a collection of drama films ranging from disaster survival, epic western, historical biographical, romantic, and psychological thriller. these films explore themes of love, loss, personal struggles, and the human condition. romance: summary: a collection of romantic movies from various genres including drama, comedy, musical, and fantasy. these films explore themes of love and relationships, featuring a mix of well-known actors and diverse storylines. scifi: summary: a collection of sci-fi films ranging from space operas to post-apocalyptic adventures, with elements of cyberpunk and dystopia. the movies explore themes of technology, survival, and thrilling action, featuring memorable characters and imaginative settings. thriller: summary: a collection of thrilling movies with elements of crime, suspense, and science fiction. the films feature a variety of genres including erotic thriller, cyberpunk, and independent drama. the cast includes notable actors such as ray liotta, linda fiorent crime: summary: a collection of crime films from the mid-90s, including gangster comedies, epic crime dramas, cyberpunk thrillers, and action-packed sci-fi flicks. comedy: summary: a collection of comedy films spanning different themes and genres, including children's comedy, adventure comedy fantasy, prank calls, historical comedy-drama, action comedy, romantic comedy, and farce black comedy. children: summary: a collection of coming-of-age, fantasy, adventure, comedy, and family films that will entertain children and provide a fun and enjoyable experience. adventure: summary: adventure movies from the 1990s with a mix of drama, fantasy, and superhero themes. animation: summary: animated films that belong to the animation genre, providing entertainment with adventure, music, and historical themes. fantasy: summary: a collection of fantasy films ranging from family adventures to magical realism, including stories about mythical creatures, mystical worlds, and extraordinary quests. documentary: summary: a collection of documentary films exploring various subjects, including basketball dreams, mockumentary, hip-hop music, hollywood's infamous madam, fashion models, and notable individuals like nico and jean seberg. the films offer a glimpse into different worlds mystery: summary: a collection of mysterious and suspenseful films that explore crime, psychological thrillers, and science fiction. these movies delve into the world of detectives, investigations, and the after-effects of unexpected events. horror: summary: a collection of horror films that explore vampires, psychological thrillers, and supernatural elements. a vampire gothic horror, a vampire black comedy, a psychological thriller, an action horror, a fantasy thriller, a direct-to-video horror, and a war: summary: a collection of war-inspired films various genres, including action thrillers, historical dramas, biographical dramas, satirical comedies, and dramatic portrayals of real-life events.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/mila/e/emiliano.penaloza/llm4rec/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2624: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/home/mila/e/emiliano.penaloza/LLM4REC/notebooks/../StyleTransfer/scorer.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  total_scores = torch.tensor(fluency_scores) * torch.tensor(sim_scores) * torch.tensor(style_scores)\n",
      "/home/mila/e/emiliano.penaloza/LLM4REC/notebooks/../StyleTransfer/scorer.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  total_scores = torch.tensor(style_scores)\n",
      "going through styles:   0%|          | 0/3 [01:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mila/e/emiliano.penaloza/LLM4REC/notebooks/model_testing.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-c011.server.mila.quebec/home/mila/e/emiliano.penaloza/LLM4REC/notebooks/model_testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m ref_new_batch_data\u001b[39m=\u001b[39mref_news[idx]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-c011.server.mila.quebec/home/mila/e/emiliano.penaloza/LLM4REC/notebooks/model_testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Calculating the acceptance probability\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-c011.server.mila.quebec/home/mila/e/emiliano.penaloza/LLM4REC/notebooks/model_testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m ref_old_score, ref_new_score, new_style_labels,_,pos_new,pos_old \\\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcn-c011.server.mila.quebec/home/mila/e/emiliano.penaloza/LLM4REC/notebooks/model_testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m=\u001b[39m sahc\u001b[39m.\u001b[39;49macceptance_prob(ref_new_batch_data, ref_olds, ref_oris, state_vec,style_ranker,movie_id \u001b[39m=\u001b[39;49m movie_id,user_id \u001b[39m=\u001b[39;49m i)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-c011.server.mila.quebec/home/mila/e/emiliano.penaloza/LLM4REC/notebooks/model_testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m ref_hat \u001b[39m=\u001b[39m ref_new_batch_data\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcn-c011.server.mila.quebec/home/mila/e/emiliano.penaloza/LLM4REC/notebooks/model_testing.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m new_style_label\u001b[39m=\u001b[39mnew_style_labels\n",
      "File \u001b[0;32m~/LLM4REC/notebooks/../StyleTransfer/scorer.py:134\u001b[0m, in \u001b[0;36mSteepHC.acceptance_prob\u001b[0;34m(self, input_news, input_olds, ref_oris, state_vec, style_scorer, model, movie_id, user_id)\u001b[0m\n\u001b[1;32m    129\u001b[0m ref_old_score, preds_old \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscorer(input_olds, ref_oris, state_vec,style_scorer,model \u001b[39m=\u001b[39m model,user_id \u001b[39m=\u001b[39m user_id,movie_id \u001b[39m=\u001b[39m movie_id)\n\u001b[1;32m    132\u001b[0m pos_old \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(preds_old\u001b[39m==\u001b[39m movie_id)\n\u001b[0;32m--> 134\u001b[0m ref_new_scores, preds_new\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscorer(input_news,ref_oris,state_vec,style_scorer,user_id\u001b[39m=\u001b[39;49m user_id,movie_id \u001b[39m=\u001b[39;49m movie_id)\n\u001b[1;32m    135\u001b[0m pos_new \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(preds_new \u001b[39m==\u001b[39m movie_id)\n\u001b[1;32m    139\u001b[0m ref_new_score\u001b[39m=\u001b[39mref_new_scores\n",
      "File \u001b[0;32m~/LLM4REC/notebooks/../StyleTransfer/scorer.py:122\u001b[0m, in \u001b[0;36mSteepHC.scorer\u001b[0;34m(self, input_news, ref_oris, state_vec, style_scorer, model, user_id, movie_id)\u001b[0m\n\u001b[1;32m    119\u001b[0m fluency_scores\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfluency_scorer(input_news) \u001b[39m# input-news, ref_oris-->[\"I like you\"]\u001b[39;00m\n\u001b[1;32m    120\u001b[0m style_scores,style_labels\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstyle_scorer(input_news) \u001b[39mif\u001b[39;00m style_scorer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m style_scorer(input_news,movie_id\u001b[39m=\u001b[39mmovie_id,user_id\u001b[39m=\u001b[39muser_id,model\u001b[39m=\u001b[39mmodel) \u001b[39m# input-news, ref_oris-->[\"I like you\"\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m sim_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msemantic_scorer(input_news, ref_oris, state_vec)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m    123\u001b[0m total_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(fluency_scores) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mtensor(sim_scores) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mtensor(style_scores)\n\u001b[1;32m    124\u001b[0m total_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(style_scores)\n",
      "File \u001b[0;32m~/LLM4REC/notebooks/../StyleTransfer/scorer.py:108\u001b[0m, in \u001b[0;36mSteepHC.semantic_scorer\u001b[0;34m(self, ref_news, ref_olds, state_vec)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msemantic_scorer\u001b[39m(\u001b[39mself\u001b[39m,ref_news, ref_olds,state_vec\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 108\u001b[0m     ref_new_embeds, mean_new_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meditor\u001b[39m.\u001b[39;49mget_contextual_word_embeddings(ref_news)\n\u001b[1;32m    109\u001b[0m     ref_old_embeds, mean_old_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meditor\u001b[39m.\u001b[39mget_contextual_word_embeddings(ref_olds)\n\u001b[1;32m    111\u001b[0m     kw_sim\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeyword_sim(ref_new_embeds,ref_old_embeds,state_vec)\n",
      "File \u001b[0;32m~/LLM4REC/notebooks/../StyleTransfer/editor.py:195\u001b[0m, in \u001b[0;36mRobertaEditor.get_contextual_word_embeddings\u001b[0;34m(self, input_texts)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_contextual_word_embeddings\u001b[39m(\u001b[39mself\u001b[39m, input_texts):\n\u001b[1;32m    192\u001b[0m     inputs \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(input_texts, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m--> 195\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs, output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    196\u001b[0m     sentence_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_pooling(outputs, inputs[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    197\u001b[0m     hidden_states \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mhidden_states[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][:, \u001b[39m1\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_len\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, :]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1087\u001b[0m, in \u001b[0;36mRobertaForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[39m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[39m    Used to hide legacy arguments that have been deprecated.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1087\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[1;32m   1088\u001b[0m     input_ids,\n\u001b[1;32m   1089\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1090\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1091\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1092\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1093\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1094\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1095\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1096\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1097\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1098\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1099\u001b[0m )\n\u001b[1;32m   1100\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1101\u001b[0m prediction_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(sequence_output)\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:847\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    838\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    840\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    841\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    842\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    845\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    846\u001b[0m )\n\u001b[0;32m--> 847\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    848\u001b[0m     embedding_output,\n\u001b[1;32m    849\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    850\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    851\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    852\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    853\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    854\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    855\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    856\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    857\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    858\u001b[0m )\n\u001b[1;32m    859\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    860\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:529\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    520\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    521\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    522\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    527\u001b[0m     )\n\u001b[1;32m    528\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    530\u001b[0m         hidden_states,\n\u001b[1;32m    531\u001b[0m         attention_mask,\n\u001b[1;32m    532\u001b[0m         layer_head_mask,\n\u001b[1;32m    533\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    534\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    535\u001b[0m         past_key_value,\n\u001b[1;32m    536\u001b[0m         output_attentions,\n\u001b[1;32m    537\u001b[0m     )\n\u001b[1;32m    539\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    540\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:455\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    452\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    453\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 455\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    456\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    457\u001b[0m )\n\u001b[1;32m    458\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    460\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/transformers/pytorch_utils.py:240\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:468\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m    467\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 468\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[1;32m    469\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:379\u001b[0m, in \u001b[0;36mRobertaOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 379\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    380\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    381\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/llm4rec/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "with open(of_dir + output_file, 'w', encoding='utf8') , torch.no_grad():\n",
    "    for i in range(len(data)):\n",
    "        batch_data = data[i]\n",
    "\n",
    "\n",
    "        for k, v in word_pairs.items():\n",
    "            batch_data = batch_data.strip().lower().replace(k, v)\n",
    "        \n",
    "        ref_oris = ref_olds = batch_data\n",
    "        state_vec, _ = editor.state_vec([ref_olds])\n",
    "\n",
    "        break_flag = False\n",
    "        max_score=-np.inf\n",
    "        step_max_score_list=[-np.inf]\n",
    "\n",
    "        max_len=len(batch_data.split())\n",
    "        select_sent = None\n",
    "        movie_id = rankings[i,19]\n",
    "        \n",
    "        \n",
    "        for step in range(args.max_steps):\n",
    "            indices_of_words_with_colon = do_not_edit(ref_olds)\n",
    "            sampled_indices = random.sample(range(max_len), 1)\n",
    "            input_tuples = [[[ref_olds],[ops],[positions],bsz,max_len]\n",
    "                                                    for positions in sampled_indices if positions not in indices_of_words_with_colon for ops in [0,1,2]]\n",
    "\n",
    "\n",
    "            ref_news = [editor.edit(*inp)for inp in tqdm(input_tuples,desc = \"Making Edits\")]\n",
    "\n",
    "            \n",
    "            for idx in ( pbar := tqdm(range(len(ref_news)),desc = 'going through styles')):\n",
    "\n",
    "                ref_new_batch_data=ref_news[idx]\n",
    "               \n",
    "\n",
    "                # Calculating the acceptance probability\n",
    "\n",
    "\n",
    "                ref_old_score, ref_new_score, new_style_labels,_,pos_new,pos_old \\\n",
    "                    = sahc.acceptance_prob(ref_new_batch_data, ref_olds, ref_oris, state_vec,style_ranker,movie_id = movie_id,user_id = i)\n",
    "\n",
    "                ref_hat = ref_new_batch_data\n",
    "\n",
    "               \n",
    "                new_style_label=new_style_labels\n",
    "                \n",
    "                # Updating the maximum score and selected sentence\n",
    "           \n",
    "                if ref_new_score>max_score and ref_new_score>ref_old_score:\n",
    "                    select_sent = ref_hat\n",
    "                    max_score=ref_new_score\n",
    "                    print(f\"New Score {ref_new_score=}\")\n",
    "                    \n",
    "                pbar.set_description(f'score = {ref_new_score}')\n",
    "\n",
    "                if args.early_stop == True and new_style_label == 1:\n",
    "                        print(f\"{new_style_label=}\")\n",
    "                        select_sent = ref_hat\n",
    "                        print_es()\n",
    "                        break_flag = True\n",
    "                        break\n",
    "            # Checking if the current score is larger than previous max score\n",
    "       \n",
    "            if max_score>=step_max_score_list[step]: \n",
    "                print(\"hill climbing!\")\n",
    "                logging.info(\"hill climbing!\")\n",
    "                if select_sent is None: \n",
    "                    random_draw = random.sample(range(len(input_tuples)),1)\n",
    "                    print('randomly drawing')\n",
    "                    select_sent = ref_news[random_draw[0]]\n",
    "\n",
    "                    # find_string_differences(select_sent[0],ref_oris[0])\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "                ref_olds = select_sent\n",
    "\n",
    "                pp(pos_new)\n",
    "                pp(pos_old)\n",
    "                result_d[i] = {'old' : ref_oris, 'new':select_sent,'movie' : movie_id,'steps':step}\n",
    "\n",
    "                    \n",
    "                step_max_score_list.append(max_score)\n",
    "            else:\n",
    "                print(\"don't climb, stop!\")\n",
    "                logging.info(\"don't climb, stop!\")\n",
    "                break_flag=True\n",
    "            if break_flag:\n",
    "                steps = step\n",
    "                break\n",
    "        if break_flag:\n",
    "            select_sent = select_sent\n",
    "\n",
    "\n",
    "        logging.info('climb {} steps, the selected sentence is: {}'.format(step+1,select_sent))\n",
    "        print('climb {} steps, the selected sentence is: {}'.format(step+1,select_sent))\n",
    "        print(f'The original sentence is: {ref_oris} ')\n",
    "        break \n",
    "    \n",
    "with open('./result_dict.pkl','wb+') as f:\n",
    "    pickle.dump(result_d,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_s1[i]='I'\n",
      " words_s2[k]='I' 0\n",
      "words_s1[i]='love'\n",
      " words_s2[k]='love' 1\n",
      "words_s1[i]='llamas'\n",
      " words_s2[k]='coffee' 2\n",
      "words_s1[i]='in'\n",
      " words_s2[k]='in' 3\n",
      "words_s1[i]='the'\n",
      " words_s2[k]='the' 4\n",
      "words_s1[i]='mornings'\n",
      " words_s2[k]='mornings' 5\n",
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "def find_different_word_indices(s1, s2):\n",
    "    # Split the strings into lists of words\n",
    "    words_s1 = s1.split()\n",
    "    words_s2 = s2.split()\n",
    "\n",
    "    # Find the minimum length of the two lists\n",
    "    min_len = min(len(words_s1), len(words_s2))\n",
    "\n",
    "    # Initialize a list to store the indices of differences\n",
    "    different_indices = []\n",
    "\n",
    "    # Iterate through each word and compare\n",
    "    i = 0\n",
    "    k=0\n",
    "    while i < len(words_s1):\n",
    "        print(f\"{words_s1[i]=}\")\n",
    "        print(f\"{ words_s2[k]=}\",k)\n",
    "        while  i < len(words_s1) and words_s1[i] != words_s2[k]:\n",
    "            different_indices.append(i)\n",
    "            i += 1\n",
    "        i+=1\n",
    "        k+=1\n",
    "\n",
    "    return different_indices\n",
    "\n",
    "# Example usage:\n",
    "s1 = \"I love llamas and coffee in the mornings\"\n",
    "s2 = \"I love coffee in the mornings\"\n",
    "\n",
    "result = find_different_word_indices(s1, s2)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have two strings for example (but not limited to ) s1 = \"I love llamas and coffee in the mornings\" and s2 = \"I love coffee in the nights\" \n",
    "\n",
    "Given two strings I want to find the indeces at which they are different in s1 for this it would be [2,3,7]. Write such an alorithm in python please"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
