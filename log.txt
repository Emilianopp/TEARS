INFO:openai:error_code=context_length_exceeded error_message="This model's maximum context length is 128000 tokens. However, your messages resulted in 147282 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False
INFO:openai:error_code=context_length_exceeded error_message="This model's maximum context length is 128000 tokens. However, your messages resulted in 147282 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False
INFO:openai:error_code=context_length_exceeded error_message="This model's maximum context length is 128000 tokens. However, your messages resulted in 147089 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False
INFO:openai:error_code=context_length_exceeded error_message="This model's maximum context length is 128000 tokens. However, your messages resulted in 145442 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False
INFO:openai:error_code=context_length_exceeded error_message="This model's maximum context length is 128000 tokens. However, your messages resulted in 129444 tokens. Please reduce the length of the messages." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False
